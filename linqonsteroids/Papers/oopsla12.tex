\documentclass{article}
\usepackage{amssymb,amsmath}
\usepackage{ifxetex,ifluatex}
\ifxetex
  \usepackage{fontspec,xltxtra,xunicode}
  \defaultfontfeatures{Mapping=tex-text,Scale=MatchLowercase}
\else
  \ifluatex
    \usepackage{fontspec}
    \defaultfontfeatures{Mapping=tex-text,Scale=MatchLowercase}
  \else
    \usepackage[utf8]{inputenc}
    \usepackage[T1]{fontenc}
  \fi
\fi
\usepackage{natbib}
\bibliographystyle{plainnat}
\ifxetex
  \usepackage[setpagesize=false, % page size defined by xetex
              unicode=false, % unicode breaks when used with xetex
              xetex]{hyperref}
\else
  \usepackage[unicode=true]{hyperref}
\fi
\hypersetup{breaklinks=true, pdfborder={0 0 0}}
\newcommand{\textsubscr}[1]{\ensuremath{_{\scriptsize\textrm{#1}}}}
\setlength{\parindent}{0pt}
\setlength{\parskip}{6pt plus 2pt minus 1pt}
\setlength{\emergencystretch}{3em}  % prevent overfull lines
\setcounter{secnumdepth}{0}

\title{Optimized queries over in-memory collections}
\author{Paolo G. Giarrusso, Klaus Ostermann}
\input{macros.tex}

\begin{document}
\maketitle

 \newcommand{\intersect}{\wedge}
\section{Introduction}

Many computations in typical programs extract information from
collections. Higher-order operators allow formulating many such
computations as queries; a collection library provides in other words a
DSEL of queries over collections, which we call the query DSEL.

Research in query processing in database has identified many
optimizations which afford great speedups, from high-level restructuring
to index application and incremental view maintenance, yet the typical
program does not take advantage of them for processing over in-memory
collection, because performing these optimizations by hand leads to a
complex, error-prone and hard-to-maintain restructuring of the original
program. Scala offers operators like \texttt{map}, \texttt{flatMap},
\texttt{withFilter} and \texttt{union}, which are present in different
form in many functional languages, together with for comprehensions,
similar to list comprehensions in other languages: they are a form of
syntactic sugar for accessing \texttt{map}, \texttt{flatMap} and
\texttt{withFilter}. We consider these operators to form a DSEL for
queries over collection. We reimplement this DSEL to allow optimization
of queries, we implement a few significant ones, and show that they
provide a significant speedup with an evaluation on (to be determined).
We first design and implement a deep embedding of a portion of this
DSEL. On top of this deep embedding, we implement some simple
optimizations as a first step.

One of the design goals for this DSEL is that embedded queries should be
as close as possible to their native equivalent, to simplify
transforming a native query into an embedded one. Ideally, querying a
``smart'' collection instead of a native one should be enough to ensure
to produce a representation of the query instead of executing it;
however, a query representation needs to be then converted explicitly to
its result. However, Scala does not support natively expression trees,
which are used in C\# to achieve this goal. We instead provide an
emulation for them, based on user-defined implicit conversions, which we
later describe. The surface syntax is quite close to Scala in many
regards, but some areas show significant limitations; in other cases,
providing a usable surface syntax is made more complex by limitations of
Scala's type inference; one of our goals is to not require the user to
supply more type annotations than it would need if expression trees were
natively supported.

%Another possibility would be to publish this work in a more complete
%form. The rest of this paper is a draft which follows this idea. \% The
%above is not really true anymore. \# Introduction Many computations in
%typical programs extract information from collections. Higher-order
%operators allow formulating many such computations as queries; a
%collection library provides in other words a DSEL of queries over
%collections, which we call the query DSEL.

It is often desirable to optimize execution of queries using a variety
of approaches. For instance, some queries are often re-executed after
changes on the original collections; other queries might be executed
faster by maintaining additional data structures, like indexes over the
original collections; yet other queries might be executed faster simply
by restructuring the query before execution. To implement these
optimizations, we embed the query DSEL \emph{deeply}, so that our
library constructs in-memory representation of queries in form of
abstract syntax trees before executing them. These ASTs can then be
subject to optimizations before being executed on in-memory collections.
We propose a deeply-embedded Scala DSEL for expressing queries over
in-memory collections with the following desirable properties:

\begin{itemize}
\item
  the query language is based on a hierarchical data model and the
  associated monadic query language, like the one used for Scala for
  comprehension, and similarly to the one described by Meijer and
  Biederman (2011) and Fegaras and Maier (2000)
\item
  queries are expressed using for comprehensions
\item
  queries can be interpreted with a very small overhead compared to
  queries expressed directly using Scala's collection library
\item
  queries can have, as results, both Traversable, Set and Map (support
  for Seq should be possible, too)
\item
  our embedding techniques (we are embedding monadic operations over
  queries) extends the techniques used in the Scala collection library
  ({[}Fighting Bitrot with Types{]}) and allows, without code
  duplication, to have very specific types for the result of different
  operations; \texttt{flatMap} on a Map will return a Map, and on a Set
  will return a Set, and so on.
\item
  results of queries over mutable collections are incrementally updated
  when the original collection changes.
\item
  indexes can be generated and applied - they are simply queries of type
  Map{[}A, B{]}, which are updated thanks to same support for IVM as
  other query results. This is only possible because our data
  representation allows to also represent different kinds of collections
  uniformly.
\item
  queries can be optimized before execution; the optimized queries,
  unlike in SQL, can still be expressed in the same language
\item
  we embed a significant subset of pure Scala, and identify problems
  which prevent using (?)
\item
  the complete pure subset of Scala can be used in the queries (? -
  elaborate), except function calls (\ldots{}) and pattern matching and
  \ldots{}
\item
  we have a partial emulation of expression trees in Scala through
  implicit conversions, and suggest approaches to extend the covered
  Scala subset.
\end{itemize}
Incremental maintenance of the results of \texttt{flatMap} is a novel
algorithm.

Our contributions are as follows: - index are identified with
materialized views representing dictionaries, and can be used
explicitly; this simplifies query optimization; - embedded queries have
precise types, just as the native Scala collections; in particular, our
embedding supports both Traversable, Set and Map; - the architecture
used to implement IVM on expression trees is novel; - we support
Incremental View Maintainance for \texttt{flatMap} operations.

The rest of this paper is organized as follows. Sec. X describes the
language we support; Sec. X describe how we embed this language; Sec. X
discusses optimizations; Sec. X evaluates our framework by
reimplementing queries from FindBugs; Sec. X discusses related work and
Sec. X discusses future work and concludes.

%\section{Our query language: first-class indexes considered helpful}
%
%Query languages for relational and OO databases allow to program queries
%declaratively, and optimizers transform those queries into execution
%plans for efficient execution. Optimizers however often fail optimizing
%a query to an efficient execution plan: In this case, developers modify
%their queries to a different form until the results of optimization are
%the expected ones. Disadvantages are: - Understanding the output of
%optimization requires understanding a different language than SQL. - The
%optimizer has access to `built-in functions' which the programmer cannot
%use. - Producing the desired execution plan might in general be
%impossible. Since the result of optimization is expressed in a quite
%different form, it is impossible to write directly an execution plan.
%The reason for this is that execution plans contain many low-level
%details, with which the developer should have nothing to do.
%
%We maintain that as many optimizations as possible should produce a
%program in the same language, that is, it should be \emph{closed}. To
%this end, we introduce a query language embedded in Scala based on
%for-comprehensions, where indexes are first-class entities like tables.
%Transformation of queries done to benefit from indexing becomes then a
%closed transformation, which can be done either automatically or
%manually. We do not maintain that \emph{all} optimizations should be
%accessible to the user. However, it should be possible to at least
%perform transformations which change the time complexity of queries.
%That is why in our proposal, indexes are made part of the logical level
%and become therefore accessible.
%
%Our prototype implementation supports only in-memory collections, but
%this already allows showing the potential of the language.
%
% This situation resembles logic programming: a declarative approach is
%proposed, but efficient execution demands manual optimizations which
%break the elegance of the original model. Functional programming
%languages, on the other side, allow expressing the intent in a clear way
%which also lends itself to reasonably efficient execution (compared to
%logic programming) and to further optimizations.

\section{Representing indexes: The groupBy operator}

Indexes do not require special support; they are encoded through the
\texttt{groupBy} operator. A query of the form:

\begin{verbatim}
coll filter (x => f(x) == y)
\end{verbatim}
is semantically equivalent to a query which builds an index first with
the result of applying \texttt{f} to elements of \texttt{coll}, and then
selecting the entry for \texttt{y}:

\begin{verbatim}
coll groupBy f apply y
\end{verbatim}
What the optimizer does is (a variant of common subexpression
elimination) between the resulting query and the keys of a map existing
precomputed expressions. A repository contains a map from queries to
their evaluated results (XXX: it should be incrementally maintained
queries!).

XXX: show a query that we can help using indexing.

\subsection{Indexes for nested objects}

Queries often traverse multiple objects, and more complex index
organizations are needed. \citet{Bertino89} describe three index
organizations for this scenario, together with the corresponding
optimizations to use them: nested indexes, path indexes and
multiindexes. Nested indexes require reverse references between objects
to be maintained, but since we do not maintain reverse references, we
exclude nested indexes from further discussion. We can readily use
multiple groupBy indexes together to encode multiindexes
\citep{Bertino89}; our framework allows defining also path indexes
through specific operators.

\section{A few running examples:}

Example 1 - a join expressed through a set comprehension, as a filtered
Cartesian product (expressed through \texttt{flatMap}):

\begin{verbatim}
for (i <- coll1;
      j <- coll2;
      if i.field1 === j.field2)
  yield (i, j)
\end{verbatim}
Example 2 - a Cartesian product query which cannot be transformed into a
join - it could be manually rewritten though:

\begin{verbatim}
for (i <- coll1;
      j <- coll2;
      if i.foo + j.bar === 3)
  yield (i, j)
\end{verbatim}
Example 3 - a query which could not be expressed as a Cartesian product:

\begin{verbatim}
for (i <- coll1;
      j <- i.divisors;
      if i.foo + j.bar === 3)
  yield (i, j)
\end{verbatim}
\section{Operators}

\subsection{Higher-order operators from relational algebra}

\begin{itemize}
\item
  Join: can be expressed through \texttt{flatMap}, which can be executed
  directly (similarly to a nested-loop join) or converted to a specific
  \texttt{join} node.
\item
  Selection: becomes \texttt{withFilter}.
\item
  Projection: becomes \texttt{map}.
\item
  Rename: since it makes less sense as such, it becomes \texttt{map} as
  well.
\item
  Aggregation: becomes \texttt{fold}.
\end{itemize}
\subsection{Set basic operators from logic and relational algebra}

\begin{itemize}
\item
  Set union: cannot be expressed through other operators
\item
  Set difference can be expressed in the base language through
  withFilter and forall (in time O($N^2$)), but also with a specific,
  direct operator, which can be executed similarly to an anti-join.
\item
  Set intersection: can be expressed through set difference
  ($A \intersect B = A - (A - B)$) or through a join. but probably
  should be expressed directly, not through other operators.
\end{itemize}
Set intersection and set difference allow unseating collections built
within withFilter operations.

It could be useful to have a let operation to support directly hoisting
out of loops.

\subsection{Other kinds of joins}

Semi-joins, anti-joins.

\subsection{IVM properties of those operators}

Set union, selection and mapping are completely self-maintainable: that
is, not even the result is needed for self-maintenance. Tables used in
filters, instead, must be materialized to allow self-maintenance; the
result, again, is not needed. \texttt{flatMap} is more complex. Results
of \texttt{flatMap} require instead to store part of the results.

\section{Expression trees and nodes}

We reify expression as expression trees. Each term of type \texttt{T} is
represented by a node \texttt{n} with type \texttt{Exp{[}T{]}};
\texttt{n.subterms} returns a list of subterms, each of type
\texttt{Exp{[}S{]} forSome \{type S\}}, but for different \texttt{S}.
The simplest node is
\texttt{case class Const{[}T{]}(t: T) extends Exp{[}T{]}}. Note that
\texttt{Const} nodes have no subterms - they just contain an evaluated
expression.

Lambda abstractions have type \texttt{Exp{[}S =\textgreater{} T{]}}.
Values of function type (of type \texttt{S =\textgreater{} T}) can be
lifted through \texttt{Const}; in addition, we support higher-order
abstract syntax (HOAS) and thus embed a term constructor
\texttt{FuncExp} (classically called \texttt{Lam}), of type
\texttt{(Exp{[}S{]} =\textgreater{} Exp{[}T{]}) =\textgreater{} Exp{[}S =\textgreater{} T{]}};
however, we allow converting these terms to first-order abstract syntax
(FOAS) through a standard trick; they have a single subterm, their body,
of type \texttt{Exp{[}T{]}}, which is an open term containing also terms
of type \texttt{TypedVar{[}S{]}}. This This conversion is always done
for three reasons:

\begin{itemize}
\item
  it removes the interpretative overhead due, e.g., to function
  composition and so on (see also higher), through \emph{normalization
  by evaluation} (XXX add citations). See also ``Building blocks for
  performance oriented DSLs'', where they do the same kind of trick to
  remove overhead from higher-order functions, even though they do not
  cite normalization by evaluation. {[}XXX note: it is not appropriate
  to cite Danvy's paper here, since \emph{their} normalization by
  evaluation is not what we need.{]}.
\item
  it catches early exotic terms, which call interpret() -
  \texttt{interpret()} will be called on open terms and throw an
  exception when recursing on TypedVar{[}S{]} terms. \%(there's a
  citation for that in Tillmann's TSR paper or in the ``Boxes go
  bananas'' paper)
\item
  a FOAS representation allows performing optimization on function
  bodies.
\end{itemize}
What is not possible efficiently, to the best of our knowledge, is to
convert FOAS back to HOAS. Given \texttt{e: Exp{[}T{]}} containing
\texttt{v: TypedVar{[}S{]}}, the body can be expressed as
\texttt{(x: Exp{[}S{]}) =\textgreater{} e.substVar(v, x)}, which
contains a substitution at runtime.

Note, moreover, that while the interface of our representation is
well-typed and type-safe, its internals are well-typed but not
automatically type-safe; in other words, the compiler does not guarantee
that our code is safe, because in the implementation we rely on erasure
and employ casts. We thus need to prove separately that the
implementation is type-safe. However, this is common to most other
implementations of expression trees, which rely on an untyped core tree
wrapped through a phantom type.

\subsection{Evaluation}

Closed terms \%or ``Expression trees representing closed terms''? I need
to ensure, before in the paper, that I can use the simpler language.
might be evaluated by calling on their root node the method
\texttt{Exp{[}T{]}.expResult(): T}, which returns the result of the
expression. Its default implementation simply delegates to the abstract
method \texttt{private{[}ivm{]} def Exp{[}T{]}.interpret(): T}, which
evaluates the expression node it is invoked on; each concrete expression
node must provide an implementation. However,
\texttt{Exp{[}T{]}.expResult(): T} might also be overridden, for
instance to cache its result or maintain it incrementally, while
\texttt{interpret()} always reevaluates the content. //XXX: not true for
Queryable, fix this. The recursion is done by calling
\texttt{expResult()} to reuse any cached results. //XXX: fix this too.
Interpretation is in general side-effect-free, with a few exceptions
related to incremental view maintenance. Environments is represented as
a \texttt{HashMap{[}Int, Any{]}}; during interpretation, the topmost
environment is stored inside a thread-local global variable and not
passed through interpreters. When evaluating the body of a closure, we
save the current environment on the metalanguage stack, add a new
binding to the environment saved in the closure and use the result to
replace the current environment, evaluate the body and then
\textsubscr{\ensuremath{\sim}}
\begin{verbatim}
class FuncExpInt[S, T](val foasBody: Exp[T], v: TypedVar[S]) extends FuncExp[S, T](…) {
  override def interpret(): S => T = {
    //Close over the current environment, and ensure it is stored in the returned closure.
    val env = FuncExpInt.env.get()
    z => FuncExpInt.env.withValue(env + (v.id -> z))(foasBody.interpret())
  }
}

class ScalaThreadLocal[T](v: => T) extends java.lang.ThreadLocal[T] {
  //...
  def withValue[U](tempV: T)(toCompute: => U) = {
    val old = get()

    set(tempV)
    val res = toCompute
    set(old)
    res
  }
}
\end{verbatim}
Thus,
\texttt{ScalaThreadLocal.withValue} reuses the host-language stack as
the stack of our interpreter. Open terms might not be evaluated;
consequently, if \texttt{x: Var} then \texttt{x.interpret()} fails,
unless a binding for \texttt{x} exists in the current environment.

\section{Incremental view maintenance}

\subsection{Architecture}

Our model for incremental view maintenance (IVM) support is based on the
Observer pattern (TODO maybe reference?). The Scala collection library
defines a reusable framework to support this pattern, but we use a
variant of it. The two main roles are fulfilled by traits Publisher and
Subscriber. Definitions follow {[}are provided in Fig. x{]}:

\begin{verbatim}
trait Publisher[+Evt, +Pub <: Publisher[Evt, Pub]] {
  type Sub = Subscriber[Evt, Pub]

  def addSubscriber(sub: Sub)
  def removeSubscriber(sub: Sub)
  protected[this] def publish(evt: Evt)
}

trait MsgSeqPublisher[+T, +Pub <: MsgSeqPublisher[T, Pub]]
  extends Publisher[Seq[Message[T]], Pub] //Simplified
\end{verbatim}
An expression node of type \texttt{Exp{[}T{]}} publishes to its
subscribers sequences of messages of type \texttt{Message{[}T{]}}:

\texttt{Exp{[}T{]} \textless{}: MsgSeqPublisher{[}T, Exp{[}T{]}{]}}

Composite expression nodes subscribe on their children expression nodes.
{[}Is this what we implement? It's not so simple!{]}

A subscriber receiving a sequence of messages can handle each of them
separately, and we provide infrastructure for that; to allow more
efficient handling of updates, a subscriber can however also analyze the
complete sequence before deciding the update strategy. For instance, if
the sequence of updates is long, it might be simpler to recompute the
result from scratch.

Many expression nodes handle messages by producing, for each message, a
sequence of messages; the generic code then produces a bigger batch by
concatenating the produced sequences:

\begin{verbatim}
trait EvtTransformerBase[-T, +U, -Repr] extends MsgSeqSubscriber[T, Repr]
  with MsgSeqPublisher[U, EvtTransformerBase[T, U, Repr]]
{
  //Contract: transforms messages, potentially executes them.
  def transformedMessages(pub: Repr, v: Message[T]): Seq[Message[U]]

  override def notify(pub: Repr, evts: Seq[Message[T]]) {
    publish(evts flatMap (transformedMessages(pub, _)))
  }
}
\end{verbatim}
Various implementation of Message{[}T{]} exist. If T is atomic, it is
appropriate to send a message which simply contains the old and new
value:

\texttt{case class UpdateVal{[}T{]}(oldV: T, newV: T) extends Message{[}T{]}}

However, this message forces subscribers to reexecute the computations
they represent. When \texttt{T} is a structured type, values of type
\texttt{Message{[}T{]}} can indicate more precisely which part of it
changed, to allow listeners to execute only the associated part of the
computation. Users can use this framework to observe result of queries
and provide updates. We want them (TODO) to be able to provide
datatype-specific messages using our framework.

Our library deals in particular with the specific case of collections,
and provides specific messages for modifications on Traversables. We
also supply reusable traits for collections publishing their
modifications, together with concrete collections using those traits.

\subsection{\texttt{FlatMap} operations}

Incremental maintenance for \texttt{FlatMap(collection, function)} nodes
requires applying \texttt{function} to each element of
\texttt{collection}, and listening on both \texttt{collection} and the
results. However, that applies also to MapOp, only we just didn't
implement it yet.

\subsection{Recompute messages}

When an expression node is incapable of updating its result
incrementally, it can also recompute its value and propagate it with a
\texttt{Recompute} message - which just provides the new value. (XXX:
does it?)

\subsubsection{GC}

Nodes hold onto their observers through weak references and on nodes
they depend on through strong references.

\section{Related work}

\subsection{Query embeddings}

\textsc{Linq} also represents a deep embedding of queries, even for
queries An embedding of Scala within itself is Lightweight modular
staging and language virtualization. Techniques for embedding operations
on Scala collections are also used for e.g.~Scalaquery and Scala
Integrated Query (XXX citations), a Scala DSEL for queries to SQL
databases expressed using for comprehensions and additional operators.
Their data model however only considers one type of collections,
represented by the interface Iterable, because different types are not
necessary for queries on SQL databases (relational algebra does not
support different ways to group records, only different records). Our
language embedding looks more suitable for CoSQL databases and allows
expressing XXX.

Ferry is also a functional language for data queries, but it is
implemented by translation to SQL; moreover, they do not have a concept
of first-class dictionaries or indexes - XXX develop a stronger
comparison.

\subsection{Query languages for hierarchical data}

\citet{Colby90}, in ``A Recursive Algebra for Nested Relations'',
defines a data-model similar to ours, because it is also compositional.

Various techniques can be seen as allowing representing dictionaries.
For instance, a JSON object is a dictionary; since JSON and XML are
``similar'', one can argue that even XML allows representing
dictionaries, especially when those techniques are used in a
semi-structural context where no fixed schema is imposed. However,
indexes are in a sense \emph{reverse} maps, and thus are different.

In a relational database, a relation is actually also a dictionary,
mapping a value of the primary key to the whole record; however, the
language does not explicitly allow using a relation as a dictionary;
moreover, there is no uniform way to refer to both relations and
indexes.

\citet{Henglein10}, in ``Generic Multiset Programming for
Language-integrated Querying'', present an alternative framework which
allows implementing some of the same optimizations we present. In their
development however the users are supposed to write the functions used
for queries explicitly using operators exposing their structure. In our
case, instead, we emulate expression trees to allow the same
optimization to be still possible with less involvement of the user.
Their model does not reify the queries, preventing their optimization to
happen before execution time - this is sensible for the limited
optimizations they implement, but not in general. Lazy products, on the
other hand, are indeed an interesting idea which we do not support (XXX:
should we?).

\subsection{Index organizations}

\citet{Lee98} describes other indexes. We do not implement them, but
they could be represented by our interface. Moreover the path dictionary
is tuned to reduce disk I/O, not for memory operations; it is not clear
if it could be advantageous because of its reduced cache footprint (we
have no clue and don't really care, at least yet).

\subsection{Incremental View Maintenance}

\citet{Willis08}, in ``Caching and Incrementalization in the Java
language'', do not support reduce and requires a special-purpose
compiler, with the associated complexity of implementation and
integration with other extensions (cite our LDTA 2012 paper).

\subsection{Incremental computation}

\citet{Hammer11} design a semantics for self-adjusting computation for
low-level languages. Their work allow supporting a large class of
imperative programs; they trace program execution while the initial
result is being computed, producing a tree of intermediate results, and
can reevaluate this trace when the input is changed. The cost of
reevaluation in the worst case is proportional to the height of the
computation tree; thus, to support efficient incremental updates, the
computation needs to be tree-structured. For instance, updating the
result of a linear fold takes linear time if the first element is
changed, while a tree-fold takes logarithmic time (as for us). Thus, the
example code they present to compute the maximum of a vector implements
an in-place destructive tree-fold, which is a non-idiomatic
implementation in C; moreover, the programmer needs to control
explicitly memoization points to reuse computations. In other words,
their library supports incremental maintenance for arbitrary client
programs, but does not guarantee efficient performance unless the
program is engineered specifically to take advantage of their library.
Our library, instead, does not support arbitrary input programs, but
provides an extensible repository of high-level operations for which we
studied incremental maintenance algorithms. The implementor of such
operations needs to reason about incremental maintenance, but the user
is freed from such responsibility. On the other hand, we provide no
support for memoization.

\citet{Demetrescu11} provides a different model; objects can be located
in a separate store of reactive memory, and developers specify one-way,
dataflow constraints in the form of arbitrary groups of imperative
statements, which typically transform input data in reactive memory into
output data. Modifications in reactive memory are detected, and affected
dataflow constraints are re-executed as needed. This model is more
explicit than the one by \citet{Hammer11}, but similarly requires the
end developer to explicitly structure reactive computation.
\citeauthor{Demetrescu11} do not describe reusable building blocks for
incremental computation, but they describe the implementation of the
Observer pattern, so we believe that an architecture similar to ours
could in principle be implemented on top of their platform.

\citet{Burckhardt11} discuss yet another model. (XXX read).

\citet{Ramalingam93} provide an extensive bibliography of previous
approaches to incremental computation.

\section{Future work}

It could be nice to integrate this with some (transparent) support for
persistence (orthogonal persistence?), like Hibernate, to get an
embedded database library. If a remoting library could then support
remote clients, we would then have a complete DBMS. However, numerous
research challenges exist for something like this.

\section{References}

\bibliography{/Users/pgiarrusso/Documents/Research/PS-Repo/Paolo/DB}

\end{document}
