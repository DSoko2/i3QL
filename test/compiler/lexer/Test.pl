/* Tests the lexer. */

:- ensure_loaded('src/compiler/Lexer.pl').


do_tokenization(SimpleFileName,Ts,Options) :-
	atomic_list_concat(['test/compiler/lexer/data/',SimpleFileName],File),
	tokenize_file(File,Ts,Options).


:- begin_tests(lexer).

test(	string_atoms,
		[true( 
			Ts = [
				a('IllegalCharacters:()[]{},;.:|',1,0),
				a('a',2,0),
				a('aaaaaaaaaaaaaaaaaaaaaaaaVVVVVVVVVVEEEEEEERRRRRRRRRYYYYYY_LLLLLLLLLLLLLLOOOOOOOOOOOOOOOOGGGGGGGGGGGGnnnnnnnnnnnaaaaaaaaaaaammmmmmmmmmmeeeeeeee',3,0),
				a(abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ,4,0)
			]
		)]
	) :- do_tokenization('StringAtoms.pl',Ts,[]).


test(	empty_file, 
		[true(Ts=[])]
	) :- do_tokenization('Empty.pl',Ts,[]).


test(	numbers, 
		[true(Ts=[
			i(0, 1, 0),
			i(1, 3, 0),
			i(123456789, 5, 0),
			r(1.2e+11, 7, 0),
			r(1.2e+11, 9, 0),
			r(1.2e-09, 11, 0),
			r(12.34, 13, 0),
			r(1234.0, 15, 0),
			r(1234.0, 17, 0),
			r(12.34e-2, 19, 0)
			]
		)]
	) :- do_tokenization('Numbers.pl',Ts,[]).


test(	ignore_comments_while_parsing,
		[true(Ts=[
			f(a, 3, 0),
			'('(3,1),
			a(b, 3, 25),
			')'(3,26),
			a('.', 3, 27)])
		]
	) :- do_tokenization('Comments.pl',Ts,[]).


test(	report_comments,
		[true(Ts=[
			eolc(' an end of line comment', 1, 0), 
			f(a, 3, 0),
			'('(3,1),
			mlc(' an inline comment ', 3, 2),
			a(b, 3, 25),
			')'(3,26),
			a('.', 3, 27),
			mlc('\na multi-line comment\n', 5, 0)
			])
		]
	) :- do_tokenization('Comments.pl',Ts,[comments(retain_all)]).


test(	report_sc_comments,
		[true(Ts=[
			sc([
				ws('\n', 2, 3), ws('\t', 3, 0), tf('A', 3, 8), ws(' ', 3, 9), 
				tf(structured, 3, 10), ws(' ', 3, 20), tf('comment.', 3, 21), 3<29,
				tf(br, 3, 30), ws(' ', 3, 32), 3/33, 3>34, ws('\n', 3, 35),
				ws('\t', 4, 0), tf('A', 4, 8), ws(' ', 4, 9), tf('link:', 4, 10), 
				ws(' ', 4, 15), '{'(4, 16), @(4, 17), tf(link, 4, 18), 
				ws(' ', 4, 22), tf(tokenize_with_sc, 4, 23), 4/39, tf('2', 4, 40), 
				'}'(4, 41), ws('\n', 4, 42), ws('\t', 5, 0), ws('\n', 5, 8), 
				ws('\t', 6, 0), @(6, 8), tf(signature, 6, 9), ws(' ', 6, 18), 
				tf(tokenize, 6, 19), '('(6, 27), tf('Stream', 6, 28), (6, 34), 
				tf('Tokens', 6, 35), (6, 41), tf('No', 6, 42), ')'(6, 44), 
				ws('\n', 6, 45), ws('\t', 7, 0), @(7, 8), tf(arg, 7, 9), 
				ws(' ', 7, 12), tf('No', 7, 13), ws(' ', 7, 15), tf(a, 7, 16), 
				ws(' ', 7, 17), tf(number, 7, 18), ws('\n', 7, 24), ws('\t', 8, 0), 
				@(8, 8), tf(arg, 8, 9), '('(8, 12), tf(in, 8, 13), ')'(8, 15), 
				ws(' ', 8, 16), tf('Stream', 8, 17), ws(' ', 8, 23), tf(a, 8, 24), 
				ws(' ', 8, 25), tf(stream, 8, 26), ws('\n', 8, 32), ws('\t', 9, 0), 
				@(9, 8), tf(arg, 9, 9), '('(9, 12), tf(out, 9, 13), ')'(9, 16), 
				ws(' ', 9, 17), tf('Tokens', 9, 18), ws(' ', 9, 24), tf(the, 9, 25), 
				ws(' ', 9, 28), tf(tokens, 9, 29), ws('\n', 9, 35)], 2, 0)
			])
		]
	) :- do_tokenization('StructuredComments.pl',Ts,[comments(retain_sc)]).


test(	operators,
		[true(Ts=[
			a(-->, 1, 0),
			a(:-, 2, 0),
			a(:-, 3, 0), 
			a(?-, 4, 0),
			a(;, 5, 0),
			a(,, 6, 0),
			a(|, 7, 0), 
			a(->, 8, 0), 
			a(\+, 9, 0), 
			a(~, 10, 0), 
			a(<, 11, 0), 
			a(=, 12, 0), 
			a(=.., 13, 0), 
			a(=@=, 14, 0), 
			a(=:=, 15, 0), 
			a(=<, 16, 0), 
			a(==, 17, 0), 
			a(=\=, 18, 0), 
			a(>, 19, 0), 
			a(>=, 20, 0), 
			a(@<, 21, 0), 
			a(@=<, 22, 0), 
			a(@>, 23, 0), 
			a(@>=, 24, 0), 
			a(\=, 25, 0), 
			a(\==, 26, 0), 
			a(is, 27, 0), 
			a(:, 28, 0),
			a(+, 29, 0),
			a(-, 30, 0), 
			a(/\, 31, 0), 
			a(\/, 32, 0), 
			a(xor, 33, 0), 
			a(><, 34, 0), 
			a(?, 35, 0), 
			a(*, 36, 0), 
			a(/, 37, 0), 
			a(//, 38, 0), 
			a(rdiv, 39, 0),
			a(<<, 40, 0), 
			a(>>, 41, 0), 
			a(mod, 42, 0), 
			a(rem, 43, 0),
			a(**, 44, 0), 
			a(^, 45, 0), 
			a(+, 46, 0)])
		]
	) :- do_tokenization('Operators.pl',Ts,[]).


test(	operators_in_context,
		[true(Ts=[
			f(o, 1, 0), '('(1,1), a(-->, 1, 2), a(,, 1, 5), i(1, 1, 7), ')'(_,_), 
			f(o, 2, 0), '('(2,1), a(:-, 2, 2), a(,, 2, 4), i(2, 2, 6), ')'(_,_), 
			f(o, 3, 0), '('(3,1), a(:-, 3, 2), a(,, 3, 4), i(3, 3, 6), ')'(_,_), 
			f(o, 4, 0), '('(4,1), a(?-, 4, 2), a(,, 4, 4), i(4, 4, 6), ')'(_,_), 
			f(o, 5, 0), '('(5,1), a(;, 5, 2), a(,, 5, 3), i(5, 5, 5), ')'(_,_), 
			f(o, 6, 0), '('(6,1), a(,, 6, 2), a(,, 6, 3), i(6, 6, 5), ')'(_,_), 
			f(o, 7, 0), '('(7,1), a(|, 7, 2), a(,, 7, 3), i(7, 7, 5), ')'(_,_),
			f(o, 8, 0), '('(8,1), a(->, 8, 2), a(,, 8, 4), i(8, 8, 6), ')'(_,_), 
			f(o, 9, 0), '('(9,1), a(\+, 9, 2), a(,, 9, 4), i(9, 9, 6), ')'(_,_), 
			f(o, 10, 0), '('(10,1), a(~, 10, 2), a(,, 10, 3), i(10, 10, 5), ')'(_,_), 
			f(o, 11, 0), '('(11,1), a(<, 11, 2), a(,, 11, 3), i(11, 11, 5), ')'(_,_), 
			f(o, 12, 0), '('(12,1), a(=, 12, 2), a(,, 12, 3), i(12, 12, 5), ')'(_,_),
			f(o, 13, 0), '('(13,1), a(=.., 13, 2), a(,, 13, 5), i(13, 13, 7), ')'(_,_),
			f(o, 14, 0), '('(14,1), a(=@=, 14, 2), a(,, 14, 5), i(14, 14, 7), ')'(_,_),
			f(o, 15, 0), '('(15,1), a(=:=, 15, 2), a(,, 15, 5), i(15, 15, 7), ')'(_,_), 
			f(o, 16, 0), '('(16,1), a(=<, 16, 2), a(,, 16, 4), i(16, 16, 6), ')'(_,_),
			f(o, 17, 0), '('(17,1), a(==, 17, 2), a(,, 17, 4), i(17, 17, 6), ')'(_,_), 
			f(o, 18, 0), '('(18,1), a(=\=, 18, 2), a(,, 18, 5), i(18, 18, 7), ')'(_,_), 
			f(o, 19, 0), '('(19,1), a(>, 19, 2), a(,, 19, 3), i(19, 19, 5), ')'(_,_), 
			f(o, 20, 0), '('(20,1), a(>=, 20, 2), a(,, 20, 4), i(20, 20, 6), ')'(_,_), 
			f(o, 21, 0), '('(21,1), a(@<, 21, 2), a(,, 21, 4), i(21, 21, 6), ')'(_,_), 
			f(o, 22, 0), '('(22,1), a(@=<, 22, 2), a(,, 22, 5), i(22, 22, 7), ')'(_,_), 
			f(o, 23, 0), '('(23,1), a(@>, 23, 2), a(,, 23, 4), i(23, 23, 6), ')'(_,_), 
			f(o, 24, 0), '('(24,1), a(@>=, 24, 2), a(,, 24, 5), i(24, 24, 7), ')'(_,_), 
			f(o, 25, 0), '('(25,1), a(\=, 25, 2), a(,, 25, 4), i(25, 25, 6), ')'(_,_), 
			f(o, 26, 0), '('(26,1), a(\==, 26, 2), a(,, 26, 5), i(26, 26, 7), ')'(_,_),
			f(o, 27, 0), '('(27,1), a(:, 27, 2), a(,, 27, 3), i(28, 27, 5), ')'(_,_),
			f(o, 28, 0), '('(28,1), a(+, 28, 2), a(,, 28, 3), i(29, 28, 5), ')'(_,_), 
			f(o, 29, 0), '('(29,1), a(-, 29, 2), a(,, 29, 3), i(30, 29, 5), ')'(_,_),
			f(o, 30, 0), '('(30,1), a(/\, 30, 2), a(,, 30, 4), i(31, 30, 6), ')'(_,_), 
			f(o, 31, 0), '('(31,1), a(\/, 31, 2), a(,, 31, 4), i(32, 31, 6), ')'(_,_), 
			f(o, 32, 0), '('(32,1), a(><, 32, 2), a(,, 32, 4), i(34, 32, 6), ')'(_,_), 
			f(o, 33, 0), '('(33,1), a(?, 33, 2), a(,, 33, 3), i(35, 33, 5), ')'(_,_), 
			f(o, 34, 0), '('(34,1), a(*, 34, 2), a(,, 34, 3), i(36, 34, 5), ')'(_,_), 
			f(o, 35, 0), '('(35,1), a(/, 35, 2), a(,, 35, 3), i(37, 35, 5), ')'(_,_), 
			f(o, 36, 0), '('(36,1), a(//, 36, 2), a(,, 36, 4), i(38, 36, 6), ')'(_,_), 
			f(o, 37, 0), '('(37,1), a(<<, 37, 2), a(,, 37, 4), i(40, 37, 6), ')'(_,_), 
			f(o, 38, 0), '('(38,1), a(>>, 38, 2), a(,, 38, 4), i(41, 38, 6), ')'(_,_), 
			f(o, 39, 0), '('(39,1), a(**, 39, 2), a(,, 39, 4), i(44, 39, 6), ')'(_,_), 
			f(o, 40, 0), '('(40,1), a(^, 40, 2), a(,, 40, 3), i(45, 40, 5), ')'(_,_), 
			f(o, 41, 0), '('(41,1), a(+, 41, 2), a(,, 41, 3), i(46, 41, 5), ')'(_,_)
			])
		]
	) :- do_tokenization('OperatorsInContext.pl',Ts,[]).


test(rg_test_Example_pl) :- do_tokenization('Example.pl',_Ts,[]).


test(rg_test_Test_pl) :- tokenize_file('test/compiler/lexer/Test.pl',_Ts).


:- end_tests(lexer).